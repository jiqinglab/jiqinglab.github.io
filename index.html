<!DOCTYPE html>
<!-- saved from url=(0039)http://www.cbsr.ia.ac.cn/users/sfzhang/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0">
  <meta name="author" content="caohu">
  <title>Hu Cao's Homepage</title>

  <!-- CSS  -->
  <link href="./files/materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/aos.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/style.css" type="text/css" rel="stylesheet" media="screen,projection">

  <link rel="shortcut icon" href="./images/TUM_logo3.png">
<script type="text/javascript" src="./files/jquery-1.12.4.min.js.下载"></script><style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>
<body data-aos-easing="ease" data-aos-duration="400" data-aos-delay="0">
  
  <div class="navbar-fixed">

    <nav class="white">
      <div class="nav-wrapper container"><a id="logo-container" href="https://hucaofighting.github.io/#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light active" href="https://hucaofighting.github.io/#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#biography">Biography</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#news">News</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#Driving">Publications</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#preprints">Preprints</a></li> 
          <!--<li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#projects">Projects</a></li> -->
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#activities">Activities</a></li>
          <!--<li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#education">Education</a></li>-->
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#internship">Internship</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#awards">Awards</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#demos">Demos</a></li>
        </ul>
        </ul>

      </div>
    </nav>
  </div>
  

<!--==========================================
                   Profile
===========================================-->

<div id="home" class="parallax-container scrollspy">


  <div class="container row cover-block">

    <div class="profile-image-block col s12 m12 l4 center">
        <img class="responsive-img profile-photo z-depth-2" src="./images/HC3.png">
    </div>

    <div class="profile-content-block col s12 m12 l8">
        <h5 class="profile-name">Hu Cao (曹虎)</h5>

        <hr>
        
        <!--<h6 class="profile-link"><strong>Ph.D. Candidate at I6, </strong> <a href="https://www.ce.cit.tum.de/air/home/"><strong>Chair of Robotics, AI and Real-time Systems (I6)</strong></a></h6>-->
        <h6 class="profile-link"><strong>Postdoctoral Research Associate</a></h6>
        <h6 class="profile-link"><a href="https://www.ce.cit.tum.de/air/home/">Chair of Robotics, AI and Real-time Systems (I6)</a></h6>
        <h6 class="profile-link"><a href="https://www.cit.tum.de/cit/startseite/">Computation, Information and Technology (CIT)</a></h6>
        <h6 class="profile-link"><a href="https://www.tum.de/en/">Technical University of Munich (TUM), Munich, Germany 85748</a></h6>
        <h6 class="profile-link">Email: hu.cao@tum.de</h6>
        
        <h1></h1>
        
        <a href="https://scholar.google.com/citations?user=O7qS9DkAAAAJ&hl=en" target="_blank"><img class="responsive-img social-photo " src="./images/google_scholar.jpg"></a>
        
        <a href="https://github.com/HuCaoFighting" target="_blank"><img class="responsive-img social-photo " src="./images/github.jpg"></a>

        <!--<a href="./files/HuCao_CV.pdf" target="_blank"><img class="responsive-img social-photo " src="./images/cv.png"></a>-->

        <!--<a href="./images/Wechat_QR_code.jpg" target="_blank"><img class="responsive-img social-photo " src="./images/wechat.png"></a>-->

        <!--<a href="https://www.zhihu.com/people/flyyoung-68" target="_blank"><img class="responsive-img social-photo " src="./images/zhihu1.png"></a>-->

        <a href="https://www.linkedin.com/in/hu-cao-8084751a3/" target="_blank"><img class="responsive-img social-photo " src="./images/linkedin.png"></a>

        <a href="https://www.researchgate.net/profile/Hu-Cao-3" target="_blank"><img class="responsive-img social-photo " src="./images/rg.png"></a>
    
    </div>    
  
  </div>
  
  <div class="parallax"><img src="./images/homepage_bg_network.jpg" alt="Unsplashed background img 1" style="display: block; transform: translate3d(-50%, 153px, 0px);"></div>  

</div>



<!--==========================================
                   About
===========================================-->
<div class="section about-section scrollspy" id="biography">

  <div class="row container">
    <br><br>
    <div class="row">
      <div class="title">Biography</div>
      <hr>
    </div>
    
    <div class="row">
      <p>
        Hu Cao is now a postdoctoral research associate in the <a href="https://www.ce.cit.tum.de/air/home/">Chair of Robotics, AI, and Real-Time Systems</a>, at the
        <a href="https://www.tum.de/en/">Technical University of Munich</a>. 
        I obtained my Ph.D. degree from TUM, supervised by <a href="https://scholar.google.com/citations?user=-CA8QgwAAAAJ&hl=en">Prof. Alois Knoll</a>.
        Before coming to TUM, I did research at Tongji University.
        Hu Cao's research interests focus on autonomous driving, robotic grasping, and dense prediction (classification, detection, and segmentation).
      </p>
      <font color="#0000dd">
      <i>
        I am looking for highly self-motivated collaborators who are interested in autonomous driving, robotic grasping, and dense prediction. Please send me an up-to-date resume via email.
      </i>
    </font>
  </div>
</div>



<!--==========================================
                   News
===========================================-->
<div class="section news-section scrollspy" id="news">

  <div class="row container">
    <div class="row">
      <div class="title">News</div>
      <hr>
    </div>
    <div class="row">
      <ul>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 08 / 2024: &nbsp;  Our Swin-Unet ranks <b> top 3 most cited ECCV papers in five years in Google Metrics, <a href="https://scholar.google.com/citations?hl=en&vq=en&view_op=list_hcore&venue=cwIh2C-xo8kJ.2024">Link</a></b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 08 / 2024: &nbsp; One paper on 4-DOF point cloud registration is accepted by <b>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</b>
        </li>
        
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 07 / 2024: &nbsp;  Two papers on RGB-Event fusion object detection and dataset distillation are accepted by <b>ECCV 2024</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 06 / 2024: &nbsp;  One paper on lightweight fisheye object detection is accepted by <b>IROS 2024</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 06 / 2024: &nbsp; We are organizing a special issue on "Advanced Perception and Planning Technology in Robotics" for <b>Frontiers in Robotics and AI (SCI)</b>, and you are welcome to submit your original research work, <a href="https://www.frontiersin.org/research-topics/64803/perceiving-the-world-planning-the-future-advanced-perception-and-planning-technology-in-robotics/overview">Please click here for more information</a></b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 05 / 2024: &nbsp;  One paper on dimension-pooling transformer for semantic segmentation is accepted by <b>IEEE Transactions on Intelligent Transportation Systems (TITS)</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 05 / 2024: &nbsp;  One paper on vision language models in autonomous driving is accepted by <b>IEEE Transactions on Intelligent Vehicles (TIV), PDF is here, <a href="https://ieeexplore.ieee.org/abstract/document/10531702">Link</a></b>
        </li>
        
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 05 / 2024: &nbsp;  One paper on point cloud registration is accepted by <b>IEEE Transactions on Intelligent Vehicles (TIV), PDF is here, <a href="https://ieeexplore.ieee.org/abstract/document/10522957">Link</a></b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 04 / 2024: &nbsp; I am glad to share my recent talk about "Application of embodied intelligence to generalized object grasping," presented at the Joint Forum of the All German Chinese Mechatronics Engineering Society and the Computer Society 2024. <b>Video is here, <a href="https://www.koushare.com/live/details/33165">Link</a></b>
        </li>
        
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 02 / 2024: &nbsp;  One paper on collaborative semantic occupancy prediction is accepted by <b>CVPR 2024</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 10 / 2023: &nbsp; I am happy that I have been awarded as an IEEE TMI Distinguished Reviewer for <b>IEEE Transactions on Medical Imaging (TMI)</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 10 / 2023: &nbsp; One paper on efficient vision transformers is accepted by <b>IEEE Transactions on Artificial Intelligence (TAI)</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 03 / 2023: &nbsp; One paper on point set registration is accepted by <b>ISPRS Journal of Photogrammetry and Remote Sensing (ISPRS), PDF is here, <a href="https://www.sciencedirect.com/science/article/pii/S0924271623000825">Link</a></b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 03 / 2023: &nbsp; One paper on robust face alignment and landmarks is accepted by <b>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 02 / 2023: &nbsp; One paper on robust radar calibration is accepted by <b>IEEE Transactions on Intelligent Transportation Systems (TITS)</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 12 / 2022: &nbsp; We are organizing a special issue on Neurointelligence for <b>Frontiers in Neuroscience (SCI)</b>, and you are welcome to submit your original research work, <a href="https://www.frontiersin.org/research-topics/51608/advanced-methods-and-applications-for-neurointelligence">Please click here for more information</a></b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 10 / 2022: &nbsp; One paper on Efficient-Grasping is accepted by <b>IEEE/ASME Transactions on Mechatronics (T-Mech)</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 09 / 2022: &nbsp; Remote visiting the Department of Computer Science, University of Hong Kong, working with <a href="https://scholar.google.com/citations?user=4uE10I0AAAAJ&hl=en">Prof. Hengshuang Zhao</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 09 / 2022: &nbsp; We released a git to collect papers about event-based robotics (autonomous driving & robotic grasping), <a href="https://github.com/HuCaoFighting/Event-based-Vision-for-Robotics">Link</a> <img src="https://img.shields.io/github/stars/HuCaoFighting/Event-based-Vision-for-Robotics?style=social" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 08 / 2022: &nbsp; Two papers are accepted by <b>IEEE International Conference on Multisensor Fusion and Integration (MFI) 2022</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 08 / 2022: &nbsp; SwinUnet is accepted by <b>European Conference on Computer Vision-Medical Computer Vision Workshop (ECCV-MCVW), Video is here, <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&list=PLx0njZEDOxbVNpmvpmH6bHjdjmgHKfonr&index=1">Link</a></b>, 2022 
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 07 / 2022: &nbsp; Our paper (Improving Autonomous Driving with Event-Based Neuromorphic Vision) is showcased on IEEE Xplore Innovation Spotlight, which highlights the most innovative and creative research directions, <a href="https://innovate.ieee.org/innovation-spotlight/improving-autonomous-driving-with-event-based-neuromorphic-vision/">Link</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 05 / 2022: &nbsp; One paper on event-based robotic grasping is accepted by <b>IEEE Transactions on Instrumentation and Measurement (TIM)</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 03 / 2022: &nbsp; I joined Computer Engineering and Networks Laboratory, <b>ETH Zurich</b>, as an academic guest, supervised by <a href="https://scholar.google.com/citations?user=OaAKHewAAAAJ&hl=en">Prof. Lothar Thiele</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 09 / 2021: &nbsp; One paper on vehicle detection is accepted by <b>IEEE Sensors Journal</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 05 / 2021: &nbsp; A validation for u-shaped swin transformer is published as a tech report on arxiv, codes released at <a href="https://github.com/HuCaoFighting/Swin-Unet?utm_source=catalyzex.com">SwinUnet</a> <img src="https://img.shields.io/github/stars/HuCaoFighting/Swin-Unet?style=social" />
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 04 / 2021: &nbsp; Research internship at EI Innovation Lab, Huawei Cloud BU, working with <a href="https://scholar.google.com/citations?user=61b6eYkAAAAJ&hl=zh-CN">Prof. Qi Tian</a> and <a href="https://scholar.google.com/citations?user=Ud6aBAcAAAAJ&hl=zh-CN">Dr. Xiaopeng Zhang</a> and <a href="https://scholar.google.com/citations?user=-eGIgsoAAAAJ&hl=en">Dr. Dongsheng Jiang</a>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 02 / 2021: &nbsp; One paper on robotic grasping detection is accepted by <b>ICRA 2021</b>
        </li>

        <!-- <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 07 / 2020: &nbsp; One paper on parking slot detection is accepted by <b>Frontiers in Neurorobotics</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 04 / 2020: &nbsp; One paper on event-based vision for robotic grasping is accepted by <b>Frontiers in Neurorobotics</b>
        </li> -->

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 03 / 2020: &nbsp; Our work on event-based vision for autonomous driving is accepted by <b>IEEE SPM</b>
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 01 / 2020: &nbsp; I joined the chair of robotics, AI and real-time systems, <b>TUM</b>, as a Ph.D. student, supervised by <a href="https://scholar.google.com/citations?user=-CA8QgwAAAAJ&hl=en">Prof. Alois Knoll</a>
        </li>

        <!-- <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 04 / 2019: &nbsp; Our work on event fusion is accepted by <b>Frontiers in Neurorobotics</b> 
        </li> -->

       <div align='right'> <a href="./news.html" class="more" target="_blank"><i></i> <font color="#0000dd" size="2">LEARN MORE>></font> </a></div>

      </ul>
    </div>
  </div>
</div>



<!--==========================================
              Autonomous driving
===========================================-->
<div class="section driving-section scrollspy" id="Driving">

  <div class="row container">
    <div class="row">
      <div class="title">Autonomous driving <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#0000dd">[Full List]</font> </a></div>
      <hr>
    </div>

    <div><font color="blue"><b>( <sup>†</sup> indicates equal contribution, <sup>*</sup> indicates corresponding author, <sup>#</sup> indicates project lead)</b></font></div><br>


    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/crop_Architecture.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Embracing Events and Frames with Hierarchical Feature Refinement Network for Object Detection</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Zehua Zhang, Yan Xia, Xinyi Li, Jiahao Xia, Guang Chen, Alois Knoll</div>
        <div class="paper-conf"><em>European Conference on Computer Vision (ECCV) <font color="#0000dd"><b>(CCF-B, Tsinghua-A)</b></font></em>, 2024</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://arxiv.org/abs/2407.12582" target="_blank">[paper]</a>
        </div>

        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/FRN?style=social" />
          <a href="https://github.com/HuCaoFighting/FRN" target="_blank">[CAFR] </a>
         <!--  <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        </div>

      </div>
    </div>

    
    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/ATT.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Dataset Distillation by Automatic Training Trajectories</div>
        <div class="paper-author">Dai Liu, Jindong Gu, <font color="#0000dd"><b>Hu Cao</b></font>, Trinitis Carsten, Schulz Martin</div>
        <div class="paper-conf"><em>European Conference on Computer Vision (ECCV) <font color="#0000dd"><b>(CCF-B, Tsinghua-A)</b></font></em>, 2024</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://arxiv.org/abs/2407.14245" target="_blank">[paper]</a>
        </div>

        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/NiaLiu/ATT?style=social" />
          <a href="https://github.com/NiaLiu/ATT" target="_blank">[ATT] </a>
         <!--  <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        </div>

      </div>
    </div>


    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/TPAMI-Li.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Transformation Decoupling Strategy based on Screw Theory for Deterministic Point Cloud Registration with Gravity Prior</div>
        <div class="paper-author">Xinyi Li, Zijian Ma, Yinlong Liu, Walter Zimmer, <font color="#0000dd"><b>Hu Cao</b></font>, Feihu Zhang, Alois Knoll </div> 
        <div class="paper-conf"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence <font color="#0000dd"><b>(JCR Q1, SCI-I, CCF-A)</b></font></em>, 2024</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://arxiv.org/abs/2311.01432" target="_blank">[paper]</a>
        </div>
        <!-- </div> -->
       <!--  <div> -->
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/Xinyi-tum/4DOF-Registration?style=social" />
          <a href="https://github.com/Xinyi-tum/4DOF-Registration" target="_blank">[4DOF-Registration] </a>
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!--</div>-->
      <!-- </div> -->
      </div>
    </div>


    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/crop_overview.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Lightweight Fisheye Object Detection Network with Transformer-based Feature Enhancement for Autonomous Driving</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Yanpeng Li, Yinlong Liu, Xinyi Li, Guang Chen, Alois Knoll </div>
        <div class="paper-conf"><em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)<font color="#0000dd"></b></font></em>, 2024</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/9913868" target="_blank">[paper]</a>
        </div>
        <!-- </div> -->
       <!--  <div> -->
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <!-- <img src="https://img.shields.io/github/stars/HuCaoFighting/Gaussian-based-Grasping?style=social" />
          <a href="https://github.com/HuCaoFighting/Gaussian-based-Grasping" target="_blank">[Efficient-Grasping] </a> -->
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!--</div>-->
      </div>
    </div>


    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/SDPT.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">SDPT: Semantic-aware Dimension-Pooling Transformer for Image Segmentation</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Hengshuang Zhao, Dongsheng Jiang, Xiaopeng Zhang, Qi Tian, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE Transactions on Intelligent Transportation Systems <font color="#0000dd"><b>(JCR Q1, SCI-I)</b></font></em>, 2024</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/document/10584449" target="_blank">[paper]</a>
        </div>

        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/SDPT?style=social" />
          <a href="https://github.com/HuCaoFighting/SDPT" target="_blank">[SDPT] </a>
         <!--  <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        </div>

      </div>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/TIV-ZXC.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Vision Language Models in Autonomous Driving: A Survey and Outlook</div>
        <div class="paper-author">Xingcheng Zhou, Mingyu Liu, Ekim Yurtsever, Bare Luka Zagar, Walter Zimmer, <font color="#0000dd"><b>Hu Cao</b></font>, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE Transactions on Intelligent Vehicles <font color="#0000dd"><b>(JCR Q1, SCI-I)</b></font></em>, 2024</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/10531702" target="_blank">[paper]</a>
        </div>

        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/ge25nab/Awesome-VLM-AD-ITS?style=social" />
          <a href="https://github.com/ge25nab/Awesome-VLM-AD-ITS" target="_blank">[VLMAD] </a>
         <!--  <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        </div>

      </div>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/TIV-Li.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Efficient and Deterministic Search Strategy Based on Residual Projections for Point Cloud Registration with Correspondences</div>
        <div class="paper-author">Xinyi Li, <font color="#0000dd"><b>Hu Cao</b></font>, Yinlong Liu, Xueli Liu, Feihu Zhang, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE Transactions on Intelligent Vehicles <font color="#0000dd"><b>(JCR Q1, SCI-I)</b></font></em>, 2024</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/10522957" target="_blank">[paper]</a>
        </div>

      </div>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/CoHFF.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Collaborative Semantic Occupancy Prediction with Hybrid Feature Fusion in Connected Automated Vehicles</div>
        <div class="paper-author">Rui Song, Chenwei Liang, <font color="#0000dd"><b>Hu Cao</b></font>, Zhiran Yan, Walter Zimmer, Markus Gross, Andreas Festag, Alois Knoll</div>
        <div class="paper-conf"><em> IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) <font color="#0000dd"><b>(CCF-A)</b></font></em>, 2024</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://arxiv.org/abs/2402.07635" target="_blank">[paper]</a>
        </div>

        <div>
          <img class="responsive-img icon" src="./images/github.png">
          <a href="https://rruisong.github.io/publications/CoHFF/" target="_blank">[CoHFF] </a>
        </div>

      </div>
    </div>



    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/GhostMHSA2.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">GhostViT: Expediting Vision Transformers via Cheap Operations</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Zhongnan Qu, Guang Chen, Xinyi Li, Lothar Thiele, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE Transactions on Artificial Intelligence<font color="#0000dd"></b></font></em>, 2023</div> 
        <!-- <div> -->
          <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/10292927" target="_blank">[paper]</a>
        <!-- </div> -->
        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/GhostViT?style=social" />
          <a href="https://github.com/HuCaoFighting/GhostViT" target="_blank">[GhostViT] </a>
         <!--  <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!-- </div> -->
      </div>
    </div>



    <!-- <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/radar_calibration.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Globally Optimal Robust Radar Calibration in Intelligent Transportation Systems</div>
        <div class="paper-author">Xinyi Li, Yinlong Liu, Venkat, <font color="#0000dd"><b>Hu Cao</b></font>, Feihu Zhang and Alois Knoll</div> 
        <div class="paper-conf"><em>IEEE Transactions on Intelligent Transportation Systems <font color="#0000dd"><b>(Journal, JCR Q1, IF-9.551)</b></font></em>, 2023</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/10070382" target="_blank">[paper]</a>
        </div>
      -->




    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/System_Multimodal2.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Fusion-based Feature Attention Gate Component for Vehicle Detection based on Event Camera</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Jiahao Xia, Genghang Zhuang, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE Sensors Journal <font color="#0000dd"><b>(JCR Q1)</b></font></em>, 2021</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/9546775" target="_blank">[paper]</a>
        </div>

        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/FAGC?style=social" />
          <a href="https://github.com/HuCaoFighting/FAGC" target="_blank">[FAGC] </a>
         <!--  <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        </div>

      </div>
    </div>

    <!-- <hr class="driving-hr"> -->



  <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/SPM_VIS.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Event-based neuromorphic vision for autonomous driving: a paradigm shift for bio-inspired visual sensing and perception</div>
        <div class="paper-author">Guang Chen, <font color="#0000dd"><b> Hu Cao</b></font>, Jorg Conradt, Huajin Tang, Florian Rohrbein, Alois Knoll</div>
        <div class="paper-conf">IEEE Signal Processing Magazine <font color="#0000dd"><b>(JCR Q1, SCI-I), <a href="https://innovate.ieee.org/innovation-spotlight/improving-autonomous-driving-with-event-based-neuromorphic-vision/" target="_blank">[IEEE Xplore Innovation Spotlight]  </a></b></font></em>, 2020</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png"> 
          <a href="https://ieeexplore.ieee.org/abstract/document/9129849" target="_blank">[paper] </a>
        </div>

        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/Event-based-Vision-for-Robotics?style=social" />
          <a href="https://github.com/HuCaoFighting/Event-based-Vision-for-Robotics" target="_blank">[Awsome-Event-based-Vision-for-Robotics] </a>
        </div>
      </div>
    </div>

    <hr class="driving-hr">

  </div>
</div>
<!--<div align='right'> <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9" size="2">LEARN MORE>></font> </a></div> -->
</div>


</div>

<!--==========================================
              Robotic grasping
===========================================-->
<div class="section grasping-section scrollspy" id="grasping">

  <div class="row container">
    <div class="row">
      <div class="title">Robotic grasping<a href="./publications.html" class="more" target="_blank"><i></i> <font color="#0000dd">[Full List]</font> </a></div>
      <hr>
    </div>

    <div><font color="blue"><b>( <sup>†</sup> indicates equal contribution, <sup>*</sup> indicates corresponding author, <sup>#</sup> indicates project lead)</b></font></div><br>


    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/EfficientGrasp.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Efficient Grasp Detection Network with Gaussian-based Grasp Representation for Robotic Manipulation</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Zhijun Li, Qian Feng, Jianjie Lin, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE/ASME Transactions on Mechatronics <font color="#0000dd"><b>(JCR Q1, SCI-I)</b></font></em>, 2022</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/9990918" target="_blank">[paper]</a>
        </div>
        <!-- </div> -->
       <!--  <div> -->
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <!-- <img src="https://img.shields.io/github/stars/HuCaoFighting/Gaussian-based-Grasping?style=social" />
          <a href="https://github.com/HuCaoFighting/Gaussian-based-Grasping" target="_blank">[Efficient-Grasping] </a> -->
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!--</div>-->
      </div>
    </div>

    <!-- <hr class="grasping-hr"> -->



    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/System_Multimodal4.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">NeuroGrasp: Multi-modal Neural Network with Euler Region Regression for Neuromorphic Vision-based Grasp Pose Estimation</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Zhijun Li, Yingbai Hu, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE Transactions on Instrumentation and Measurement, <font color="#0000dd"><b>(JCR Q1)</b></font></em>, 2022</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/9787342" target="_blank">[paper]</a>
        </div>

        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/DVS-GraspingDataSet?style=social" />
          <a href="https://github.com/HuCaoFighting/DVS-GraspingDataSet" target="_blank">[NeuroGrasp] </a>
        </div>

      </div>
    </div>

    <!-- <hr class="grasping-hr"> -->

  

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/ResidualGrasp.jpg">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Residual Squeeze-and-Excitation Network with Multi-scale Spatial Pyramid Module for Fast Robotic Grasping Detection</div>
          <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Zhijun Li, Jianjie Lin, Alois Knoll</div>
          <div class="paper-conf">IEEE International Conference on Robotics and Automation (ICRA) <font color="#0000dd"><b>(CCF-B, Tsinghua-A)</b></font></em>, 2021</div> 
          <div>
            <img class="responsive-img icon" src="./images/pdf.png"> 
            <a href="https://ieeexplore.ieee.org/abstract/document/9561836" target="_blank">[paper] </a>
          </div>
        </div>
      </div>


      <hr class="grasping-hr">
      </div>
      </div>
      <!--<div align='right'> <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9" size="2">LEARN MORE>></font> </a></div> -->
  </div>


</div>



<!--==========================================
                   Dense prediction
===========================================-->
<div class="section Dense-section scrollspy" id="Dense">

  <div class="row container">
    <div class="row">
      <div class="title">Dense prediction<a href="./publications.html" class="more" target="_blank"><i></i> <font color="#0000dd">[Full List]</font> </a></div>
      <hr>
    </div>


    <div><font color="blue"><b>( <sup>†</sup> indicates equal contribution, <sup>*</sup> indicates corresponding author, <sup>#</sup> indicates project lead)</b></font></div><br>
   
    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/FaceLandmark2.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Robust Face Alignment via Inherent Relation Learning and Uncertainty Estimation</div>
        <div class="paper-author">Jiahao Xia, Min Xu, Haimin Zhang, Jianguo Zhang, Wenjian Huang, <font color="#0000dd"><b>Hu Cao</b></font>, Shiping Wen </div> 
        <div class="paper-conf"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence <font color="#0000dd"><b>(JCR Q1, SCI-I, CCF-A)</b></font></em>, 2023</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/10079153" target="_blank">[paper]</a>
        </div>
        <!-- </div> -->
       <!--  <div> -->
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/Jiahao-UTS/DSLPT?style=social" />
          <a href="https://github.com/Jiahao-UTS/DSLPT" target="_blank">[DSLPT] </a>
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!--</div>-->
      <!-- </div> -->
      </div>
    </div>



    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/swin_block.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Yueyue Wang, Joy Chen, Dongsheng Jiang, Xiaopeng Zhang, Qi Tian, Manning Wang</div>
        <div class="paper-conf"><em>European Conference on Computer Vision Workshops (ECCVW) <font color="#0000dd"><b> <a href="https://scholar.google.com/citations?hl=en&vq=en&view_op=list_hcore&venue=cwIh2C-xo8kJ.2024" target="_blank">[Top 3 Most Cited ECCV Papers in Five Years]  </a></b></font></em>, 2022</div> 
        <!-- <div> -->
          <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://link.springer.com/chapter/10.1007/978-3-031-25066-8_9" target="_blank">[paper]</a>
        <!-- </div> -->
        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/Swin-Unet?style=social" />
          <a href="https://github.com/HuCaoFighting/Swin-Unet" target="_blank">[Swin-Unet] </a>
          <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        </div>
      </div>
    </div>


    
    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/Fisheye.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Orientation-aware People Detection and Counting Method based on Overhead Fisheye Camera</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Boyang Peng, Linxuan Jia, Bin Li, Alois Knoll, Guang Chen</div>
        <div class="paper-conf"><em>IEEE International Conference on Multisensor Fusion and Integration (MFI)<font color="#0000dd"></b></font></em>, 2022</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/9913868" target="_blank">[paper]</a>
        </div>
        <!-- </div> -->
       <!--  <div> -->
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <!-- <img src="https://img.shields.io/github/stars/HuCaoFighting/Gaussian-based-Grasping?style=social" />
          <a href="https://github.com/HuCaoFighting/Gaussian-based-Grasping" target="_blank">[Efficient-Grasping] </a> -->
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!--</div>-->
      </div>
    </div>

    <hr class="Dense-hr">

  <!-- </div> -->
</div>
<!--<div align='right'> <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9" size="2">LEARN MORE>></font> </a></div> -->
</div>


</div>



<!--==========================================
                   Preprints
===========================================-->
<div class="section preprints-section scrollspy" id="preprints">

  <div class="row container">
    <div class="row">
      <div class="title">Preprints<a href="./publications.html" class="more" target="_blank"><i></i> <font color="#0000dd">[Full List]</font> </a></div>
      <hr>
    </div>

    <div><font color="blue"><b>( <sup>†</sup> indicates equal contribution, <sup>*</sup> indicates corresponding author, <sup>#</sup> indicates project lead)</b></font></div><br>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/ClipDomain.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">VLTSeg: Simple Transfer of CLIP-Based Vision-Language Representations for Domain Generalized Semantic Segmentation</div>
        <div class="paper-author">Hümmer Christoph, Schwonberg Manuel, Zhou Liangwei, <font color="#0000dd"><b>Hu Cao*</b></font>, Alois Knoll, Gottschalk Hanno</div>
        <!-- <div class="paper-conf"><em>IEEE Geoscience and Remote Sensing Letters <font color="red"><b>(GRSL, CCF-C)</b></font></em>, 2021</div> -->
        <!-- <div> -->
          <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
          <a href="https://arxiv.org/abs/2312.02021" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2101.10226-B31B1B.svg" /></a>
        <!-- </div> -->
       <!--  <div> -->
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <!-- <img src="https://img.shields.io/github/stars/HuCaoFighting/Gaussian-based-Grasping?style=social" />
          <a href="https://github.com/HuCaoFighting/Gaussian-based-Grasping" target="_blank">[Efficient-Grasping] </a> -->
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!--</div>-->
      </div>
    </div>

    <hr class="preprints-hr">

  </div>

</div>

<!-- ==========================================
                   Activities
=========================================== -->
<div class="section activities-section scrollspy" id="activities">
  <div class="row container">
    <div class="row">
      <div class="title">Academic Activities</div>
      <hr>

        <h5>Editor Services</h5>
        <ul>
          <li>  • Topic Editors for Frontiers in Robotics and AI (SCI), 2024</li>
          <li>  • Topic Coordinator for Frontiers in Neuroscience (SCI), 2022</li>
        </ul>

        <h5>Conference Reviewers/Program Committee member (PC)</h5>
        <ul>
          <li>  • IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR), 2024</li>
          <li>  • IEEE International Conference on Robotics and Automation (ICRA), 2021/2022/2024</li>
          <li>  • IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021/2024</li>
          <li>  • ACM Multimedia (ACM MM), 2023/2024</li>
          <li>  • Annual Meeting of the Association for Computational Linguistics (ACL), 2024</li>
          <li>  • Medical Image Computing and Computer Assisted Intervention(MICCAI), 2024</li>
          <li>  • AAAI Conference on Artificial Intelligence (AAAI), 2023/2024/2025</li>
          <li>  • European Conference on Computer Vision (ECCV), 2022/2024</li>
        </ul>

        <h5>Journal Reviewers</h5>
        <ul>
          <li>  • IEEE Transactions on Image Processing (TIP)</li>
          <li>  • IEEE Transactions on Artificial Intelligence (TAI)</li>
          <li>  • IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
          <li>  • IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
          <li>  • IEEE Transactions on Cybernetics (TCYB)</li>
          <li>  • IEEE Transactions on Automation Science and Engineering (T-ASE)</li>
          <li>  • IEEE/ASME Transactions on Mechatronics (T-Mech)</li>
          <li>  • IEEE Robotics and Automation Letters (RAL)</li>
          <li>  • IEEE Transactions on Intelligent Vehicles (TIV)</li>
          <li>  • IEEE Transactions on Industrial Electronics (TIE)</li>
          <li>  • IEEE Transactions on Consumer Electronics (TCE)</li>
          <li>  • IEEE Transactions on Industrial Informatics (TII)</li>
          <li>  • IEEE Transactions on Computational Imaging (TCI)</li>
          <li>  • IEEE Transactions on Geoscience and Remote Sensing (TGRS)</li>
          <li>  • IEEE Transactions on Instrumentation & Measurement (TIM) </li>
          <li>  • IEEE Instrumentation & Measurement Magazine (TIMM) </li>
          <li>  • IEEE Journal of Biomedical and Health Informatics (JBHI)</li>
          <li>  • IEEE Transactions on Medical Imaging (TMI)</li>
          <li>  • Medical Image Analysis (MIA)</li>
          <li>  • Pattern Recognition (PR)</li>
          <li>  • Scientific Reports</li>
          <li>  • Frontiers in Neurorobotics</li>
          <li>  • The Visual Computer</li>
          <li>  • Signal, Image and Video Processing</li>
          <li>  • Automotive Innovation</li> 
        </ul>

    </div>
  </div>
</div>


<!--==========================================
                   Education
===========================================-->
<!--<div class="section education-section scrollspy" id="education">
  <div class="row container">
    <div class="row">
      <div class="title">Education</div>
      <hr>
    </div>
    
    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://www.ahut.edu.cn/" target="_blank">
            <img src="./images/ahust.jpg" style="width:110px;height:110px;" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"></div>
          <div class="degree"><b>B.E.</b> degree from School of Mechanical Engineering, <a href="https://www.ahut.edu.cn/">Anhui University of Technology</a>, Anhui, China</div>
          <div class="date">Sep. 2013 - July 2017</div>
        </div>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://www.hnu.edu.cn/" target="_blank">
            <img src="./images/HNU.png" style="width:110px;height:110px;" align="center" class="img-responsive edu-img"> -->
            <!-- <img src="./images/iecas.jpeg" style="width:100px;height:100px;" align="center" class="img-responsive edu-img"> -->
            <!-- <img src="./images/air.png" style="width:100px;height:100px;" align="center" class="img-responsive edu-img"> -->
        <!--  </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"></div>
          <div class="degree"><b>M.E.</b> degree from <a href="http://mve.hnu.edu.cn/">College of Mechanical and Vehicle Engineering</a>, <a href="http://dmvb.hnu.edu.cn/index.htm">State key laboratory of advanced design and manufacturing for vehicle body</a> of <a href="https://www.hnu.edu.cn/">HuNan University</a>, HuNan, China</div>
          <div class="date">Sep. 2017 - July 2019</div>
        </div>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://www.tum.de/en/" target="_blank">
            <img src="./images/Tum_logo.gif" style="width:110px;height:110px;" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"><b>Ph.D.</b> in <a href="https://www.in.tum.de/i06/home/">Chair of Robotics, AI and Real-time Systems</a>, Department of Informatics</a>, <a href="https://www.tum.de/en/">Technical University of Munich</a>, Munich, Germany</div>
          <div class="date">Jan. 2020 - Present</div>
        </div>
    </div>
  </div>
</div> -->


<div class="section preprints-section scrollspy" id="internship">

  <div class="row container">
    <div class="row">
      <div class="title">Internship and Cooperation</div>
      <hr>
    </div>

        <div class="corp_item">
          <img class="corp_logo" style="height:80px;" src="./images/IIV_TJU2.jfif"> &nbsp; &nbsp;
          <!-- <img class="corp_logo" style="height:80px;" src="./images/megvii.png"> &nbsp; &nbsp;
          <img class="corp_logo" style="height:80px;" src="./images/tencentmap.png"> &nbsp; &nbsp;-->
          <img class="corp_logo" style="height:80px;" src="./images/huawei1.png"> &nbsp; &nbsp;
          <img class="corp_logo" style="height:60px;" src="./images/ETH.png">&nbsp; &nbsp;
          <img class="corp_logo" style="height:60px;" src="./images/AG.png">&nbsp; &nbsp;
          <img class="corp_logo" style="height:80px;" src="./images/HKU.png">&nbsp; &nbsp;
          <img class="corp_logo" style="height:80px;" src="./images/fortiss.png">&nbsp; &nbsp;
          <!-- <img class="corp_logo" style="height:80px;" src="./images/bytedance.png"> -->
        </div>

  </div>

</div>


<!-- ==========================================
                   Awards
=========================================== -->
<div class="section awards-section scrollspy" id="awards">
  <div class="row container">
    <div class="row">
      <div class="title">Awards</div>      
      <hr>
      <ul>
        <li>  • Distinguished Reviewer of IEEE Transactions on Medical Imaging (TMI), 2022-2023</li>
        <li>  • Outstanding Graduate of Hunan Province, 2019</li>
        <li>  • Outstanding Graduate of Hunan University, 2019</li>
        <li>  • Outstanding Graduate Student of Hunan University, 2017-2018</li>
        <li>  • Outstanding Graduate Student Leader of Hunan University, 2017-2018</li>
        <li>  • Most media Attention Award, The 3rd Lushan Cup Innovation Challenge Competition, 2018</li>
        <li>  • Second Prize, 2018 ”Haosen Pharmaceutical Cup” 5th China Graduate Smart City Technology and Creative Design Competition , 2018</li>
        <li>  • Second Prize, The 4th National ”TRIZ” Cup College Students Innovation Competition, 2016</li>
        <li>  • First Prize, The 7th National College Students Mechanical Innovation Design Competition, 2016</li>
      </ul>
    </div>
  </div>
</div>

<!-- ==========================================
                   Demo
=========================================== -->
<div class="section awards-section scrollspy" id="demos">
  <div class="row container">
    <div class="row">
      <div class="title">💻 Demos</div>      
      <hr>
      <video width="640" height="360" controls autoplay>
        <source src="./videos/ART.mp4" type="video/mp4">
      </video>
      <video width="640" height="360" controls autoplay>
        <source src="./videos/RoboticGraspingMusic.mp4" type="video/mp4">
      </video>
      <!-- <img src="https://api.star-history.com/svg?repos=yangxue0827/RotationDetection&type=Date" style="width:600px;" /> -->
      <!-- <img src="https://api.star-history.com/svg?repos=open-mmlab/mmrotate&type=Date" style="width:600px;" /> -->
    </div>
  </div>
</div>

<!--==========================================
                   Footer
===========================================-->
<footer class="page-footer grey lighten-2">
    <div class="row">
      <div class="widgetContainer" style="width:300px; margin: 0 auto;">        
        <!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=JmtGDoLvSHQtPqCWd8cr5dhSABXJqV6QbEaaA2Gp1xU'></script> -->
        <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=52alcfaz816&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>
      </div>
    </div>
    <div class="footer-copyright center black-text">
      Copyright © Hu Cao 2021
    </div>  
</footer>

<!--  Scripts-->
<script src="./files/jquery-2.1.1.min.js"></script>
<script src="./files/materialize.js"></script>
<script src="./files/aos.js"></script>
<script src="./init.js"></script>

</div><div class="jvectormap-tip"></div></body></html>
