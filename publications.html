<!DOCTYPE html>
<!-- saved from url=(0039)http://www.cbsr.ia.ac.cn/users/sfzhang/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0">
  <meta name="author" content="caohu">
  <title>Hu Cao's Homepage</title>

  <!-- CSS  -->
  <link href="./files/materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/aos.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/style.css" type="text/css" rel="stylesheet" media="screen,projection">

  <link rel="shortcut icon" href="./images/TUM_logo3.png">
<script type="text/javascript" src="./files/jquery-1.12.4.min.js.‰∏ãËΩΩ"></script><style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>
<body data-aos-easing="ease" data-aos-duration="400" data-aos-delay="0">
  
  <div class="navbar-fixed">

    <nav class="white">
      <div class="nav-wrapper container"><a id="logo-container" href="https://hucaofighting.github.io/#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light active" href="https://hucaofighting.github.io/#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#biography">Biography</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#news">News</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#Driving">Publications</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#preprints">Preprints</a></li> 
          <!--<li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#projects">Projects</a></li> -->
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#activities">Activities</a></li>
          <!--<li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#education">Education</a></li>-->
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#internship">Internship</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#awards">Awards</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://hucaofighting.github.io/#demos">Demos</a></li>
        </ul>
        </ul>

      </div>
    </nav>
  </div>
  
<div class="section preprints-section scrollspy" id="summary">

    <div class="row container">
      <div class="row">
        <div class="title">üìù Summary</div>
        <hr>
      </div>
      <div><p><b>Conference</b>: CVPR/ICCV/ECCV (1/0/2), NeurIPS/ICML/ICLR (0/0/0), RSS/ICRA/IROS/CoRL (0/1/1/0), AAAI (0), ACM MM (0)</p></div>
      <div><p><b>Journal</b>: TPAMI (2), IJCV (0), IEEE Transactions (9)</p></div>
      <div><p><b>Award</b>: ESI Hot Cited Paper (0), ESI Highly Cited Paper (0), Most Influential Paper (1)</p></div>
  
  
    </div>
  
</div>

<!--==========================================
              Autonomous driving
===========================================-->
<div class="section driving-section scrollspy" id="Driving">

  <div class="row container">
    <div class="row">
      <div class="title">Autonomous driving</div>
      <hr>
    </div>

    <div><font color="blue"><b>( <sup>‚Ä†</sup> indicates equal contribution, <sup>*</sup> indicates corresponding author, <sup>#</sup> indicates project lead)</b></font></div><br>


    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/crop_Architecture.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Embracing Events and Frames with Hierarchical Feature Refinement Network for Object Detection</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Zehua Zhang, Yan Xia, Xinyi Li, Jiahao Xia, Guang Chen, Alois Knoll</div>
        <div class="paper-conf"><em>European Conference on Computer Vision (ECCV) <font color="#0000dd"><b>(CCF-B, Tsinghua-A)</b></font></em>, 2024</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://arxiv.org/abs/2407.12582" target="_blank">[paper]</a>
        </div>

        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/FRN?style=social" />
          <a href="https://github.com/HuCaoFighting/FRN" target="_blank">[CAFR] </a>
         <!--  <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        </div>

      </div>
    </div>

    
    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/ATT.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Dataset Distillation by Automatic Training Trajectories</div>
        <div class="paper-author">Dai Liu, Jindong Gu, <font color="#0000dd"><b>Hu Cao</b></font>, Trinitis Carsten, Schulz Martin</div>
        <div class="paper-conf"><em>European Conference on Computer Vision (ECCV) <font color="#0000dd"><b>(CCF-B, Tsinghua-A)</b></font></em>, 2024</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://arxiv.org/abs/2407.14245" target="_blank">[paper]</a>
        </div>

        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/NiaLiu/ATT?style=social" />
          <a href="https://github.com/NiaLiu/ATT" target="_blank">[ATT] </a>
         <!--  <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        </div>

      </div>
    </div>


    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/TPAMI-Li.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Transformation Decoupling Strategy based on Screw Theory for Deterministic Point Cloud Registration with Gravity Prior</div>
        <div class="paper-author">Xinyi Li, Zijian Ma, Yinlong Liu, Walter Zimmer, <font color="#0000dd"><b>Hu Cao</b></font>, Feihu Zhang, Alois Knoll </div> 
        <div class="paper-conf"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence <font color="#0000dd"><b>(JCR Q1, SCI-I, CCF-A)</b></font></em>, 2024</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://arxiv.org/abs/2311.01432" target="_blank">[paper]</a>
        </div>
        <!-- </div> -->
       <!--  <div> -->
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/Xinyi-tum/4DOF-Registration?style=social" />
          <a href="https://github.com/Xinyi-tum/4DOF-Registration" target="_blank">[4DOF-Registration] </a>
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!--</div>-->
      <!-- </div> -->
      </div>
    </div>


    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/crop_overview.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Lightweight Fisheye Object Detection Network with Transformer-based Feature Enhancement for Autonomous Driving</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Yanpeng Li, Yinlong Liu, Xinyi Li, Guang Chen, Alois Knoll </div>
        <div class="paper-conf"><em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)<font color="#0000dd"></b></font></em>, 2024</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/9913868" target="_blank">[paper]</a>
        </div>
        <!-- </div> -->
       <!--  <div> -->
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <!-- <img src="https://img.shields.io/github/stars/HuCaoFighting/Gaussian-based-Grasping?style=social" />
          <a href="https://github.com/HuCaoFighting/Gaussian-based-Grasping" target="_blank">[Efficient-Grasping] </a> -->
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!--</div>-->
      </div>
    </div>


    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/SDPT.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">SDPT: Semantic-aware Dimension-Pooling Transformer for Image Segmentation</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Hengshuang Zhao, Dongsheng Jiang, Xiaopeng Zhang, Qi Tian, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE Transactions on Intelligent Transportation Systems <font color="#0000dd"><b>(JCR Q1, SCI-I)</b></font></em>, 2024</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/document/10584449" target="_blank">[paper]</a>
        </div>

        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/SDPT?style=social" />
          <a href="https://github.com/HuCaoFighting/SDPT" target="_blank">[SDPT] </a>
         <!--  <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        </div>

      </div>
    </div>


    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/TIV-ZXC.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Vision Language Models in Autonomous Driving: A Survey and Outlook</div>
        <div class="paper-author">Xingcheng Zhou, Mingyu Liu, Ekim Yurtsever, Bare Luka Zagar, Walter Zimmer, <font color="#0000dd"><b>Hu Cao</b></font>, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE Transactions on Intelligent Vehicles <font color="#0000dd"><b>(JCR Q1, SCI-I)</b></font></em>, 2024</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/10531702" target="_blank">[paper]</a>
        </div>

        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/ge25nab/Awesome-VLM-AD-ITS?style=social" />
          <a href="https://github.com/ge25nab/Awesome-VLM-AD-ITS" target="_blank">[VLMAD] </a>
         <!--  <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        </div>

      </div>
    </div>


    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/TIV-Li.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Efficient and Deterministic Search Strategy Based on Residual Projections for Point Cloud Registration with Correspondences</div>
        <div class="paper-author">Xinyi Li, <font color="#0000dd"><b>Hu Cao</b></font>, Yinlong Liu, Xueli Liu, Feihu Zhang, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE Transactions on Intelligent Vehicles <font color="#0000dd"><b>(JCR Q1, SCI-I)</b></font></em>, 2024</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/10522957" target="_blank">[paper]</a>
        </div>

      </div>
    </div>


    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/CoHFF.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Collaborative Semantic Occupancy Prediction with Hybrid Feature Fusion in Connected Automated Vehicles</div>
        <div class="paper-author">Rui Song, Chenwei Liang, <font color="#0000dd"><b>Hu Cao</b></font>, Zhiran Yan, Walter Zimmer, Markus Gross, Andreas Festag, Alois Knoll</div>
        <div class="paper-conf"><em> IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) <font color="#0000dd"><b>(CCF-A)</b></font></em>, 2024</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://arxiv.org/abs/2402.07635" target="_blank">[paper]</a>
        </div>

        <div>
          <img class="responsive-img icon" src="./images/github.png">
          <a href="https://rruisong.github.io/publications/CoHFF/" target="_blank">[CoHFF] </a>
        </div>

      </div>
    </div>



    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/GhostMHSA2.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">GhostViT: Expediting Vision Transformers via Cheap Operations</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Zhongnan Qu, Guang Chen, Xinyi Li, Lothar Thiele, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE Transactions on Artificial Intelligence<font color="#0000dd"></b></font></em>, 2023</div> 
        <!-- <div> -->
          <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/10292927" target="_blank">[paper]</a>
        <!-- </div> -->
        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/GhostViT?style=social" />
          <a href="https://github.com/HuCaoFighting/GhostViT" target="_blank">[GhostViT] </a>
         <!--  <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!-- </div> -->
      </div>
    </div>



    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/radar_calibration.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Globally Optimal Robust Radar Calibration in Intelligent Transportation Systems</div>
        <div class="paper-author">Xinyi Li, Yinlong Liu, Venkat, <font color="#0000dd"><b>Hu Cao</b></font>, Feihu Zhang and Alois Knoll</div> 
        <div class="paper-conf"><em>IEEE Transactions on Intelligent Transportation Systems <font color="#0000dd"><b>(JCR Q1, SCI-I)</b></font></em>, 2023</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/10070382" target="_blank">[paper]</a>
        </div>
      </div>
    </div>
     




    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/System_Multimodal2.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Fusion-based Feature Attention Gate Component for Vehicle Detection based on Event Camera</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Jiahao Xia, Genghang Zhuang, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE Sensors Journal <font color="#0000dd"><b>(JCR Q1)</b></font></em>, 2021</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/9546775" target="_blank">[paper]</a>
        </div>

        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/FAGC?style=social" />
          <a href="https://github.com/HuCaoFighting/FAGC" target="_blank">[FAGC] </a>
         <!--  <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        </div>

      </div>
    </div>

    <!-- <hr class="driving-hr"> -->



  <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/SPM_VIS.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Event-based neuromorphic vision for autonomous driving: a paradigm shift for bio-inspired visual sensing and perception</div>
        <div class="paper-author">Guang Chen, <font color="#0000dd"><b> Hu Cao</b></font>, Jorg Conradt, Huajin Tang, Florian Rohrbein, Alois Knoll</div>
        <div class="paper-conf">IEEE Signal Processing Magazine <font color="#0000dd"><b>(JCR Q1, SCI-I), <a href="https://innovate.ieee.org/innovation-spotlight/improving-autonomous-driving-with-event-based-neuromorphic-vision/" target="_blank">[IEEE Xplore Innovation Spotlight]  </a></b></font></em>, 2020</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png"> 
          <a href="https://ieeexplore.ieee.org/abstract/document/9129849" target="_blank">[paper] </a>
        </div>

        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/Event-based-Vision-for-Robotics?style=social" />
          <a href="https://github.com/HuCaoFighting/Event-based-Vision-for-Robotics" target="_blank">[Awsome-Event-based-Vision-for-Robotics] </a>
        </div>
      </div>
    </div>

    <hr class="driving-hr">

  </div>
</div>
<!--<div align='right'> <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9" size="2">LEARN MORE>></font> </a></div> -->
</div>


</div>

<!--==========================================
              Robotic grasping
===========================================-->
<div class="section grasping-section scrollspy" id="grasping">

  <div class="row container">
    <div class="row">
      <div class="title">Robotic grasping<a href="./publications.html" class="more" target="_blank"><i></i> <font color="#0000dd">[Full List]</font> </a></div>
      <hr>
    </div>

    <div><font color="blue"><b>( <sup>‚Ä†</sup> indicates equal contribution, <sup>*</sup> indicates corresponding author, <sup>#</sup> indicates project lead)</b></font></div><br>


    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/EfficientGrasp.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Efficient Grasp Detection Network with Gaussian-based Grasp Representation for Robotic Manipulation</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Zhijun Li, Qian Feng, Jianjie Lin, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE/ASME Transactions on Mechatronics <font color="#0000dd"><b>(JCR Q1, SCI-I)</b></font></em>, 2022</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/9990918" target="_blank">[paper]</a>
        </div>
        <!-- </div> -->
       <!--  <div> -->
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <!-- <img src="https://img.shields.io/github/stars/HuCaoFighting/Gaussian-based-Grasping?style=social" />
          <a href="https://github.com/HuCaoFighting/Gaussian-based-Grasping" target="_blank">[Efficient-Grasping] </a> -->
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!--</div>-->
      </div>
    </div>

    <!-- <hr class="grasping-hr"> -->



    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/System_Multimodal4.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">NeuroGrasp: Multi-modal Neural Network with Euler Region Regression for Neuromorphic Vision-based Grasp Pose Estimation</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Zhijun Li, Yingbai Hu, Alois Knoll</div>
        <div class="paper-conf"><em>IEEE Transactions on Instrumentation and Measurement, <font color="#0000dd"><b>(JCR Q1)</b></font></em>, 2022</div> 

        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/9787342" target="_blank">[paper]</a>
        </div>

        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/DVS-GraspingDataSet?style=social" />
          <a href="https://github.com/HuCaoFighting/DVS-GraspingDataSet" target="_blank">[NeuroGrasp] </a>
        </div>

      </div>
    </div>

    <!-- <hr class="grasping-hr"> -->

  

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/ResidualGrasp.jpg">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Residual Squeeze-and-Excitation Network with Multi-scale Spatial Pyramid Module for Fast Robotic Grasping Detection</div>
          <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Guang Chen, Zhijun Li, Jianjie Lin, Alois Knoll</div>
          <div class="paper-conf">IEEE International Conference on Robotics and Automation (ICRA) <font color="#0000dd"><b>(CCF-B, Tsinghua-A)</b></font></em>, 2021</div> 
          <div>
            <img class="responsive-img icon" src="./images/pdf.png"> 
            <a href="https://ieeexplore.ieee.org/abstract/document/9561836" target="_blank">[paper] </a>
          </div>
        </div>
      </div>


      <hr class="grasping-hr">
      </div>
      </div>
      <!--<div align='right'> <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9" size="2">LEARN MORE>></font> </a></div> -->
  </div>


</div>



<!--==========================================
                   Dense prediction
===========================================-->
<div class="section Dense-section scrollspy" id="Dense">

  <div class="row container">
    <div class="row">
      <div class="title">Dense prediction</div>
      <hr>
    </div>


    <div><font color="blue"><b>( <sup>‚Ä†</sup> indicates equal contribution, <sup>*</sup> indicates corresponding author, <sup>#</sup> indicates project lead)</b></font></div><br>
   
    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/FaceLandmark2.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Robust Face Alignment via Inherent Relation Learning and Uncertainty Estimation</div>
        <div class="paper-author">Jiahao Xia, Min Xu, Haimin Zhang, Jianguo Zhang, Wenjian Huang, <font color="#0000dd"><b>Hu Cao</b></font>, Shiping Wen </div> 
        <div class="paper-conf"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence <font color="#0000dd"><b>(JCR Q1, SCI-I, CCF-A)</b></font></em>, 2023</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/10079153" target="_blank">[paper]</a>
        </div>
        <!-- </div> -->
       <!--  <div> -->
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/Jiahao-UTS/DSLPT?style=social" />
          <a href="https://github.com/Jiahao-UTS/DSLPT" target="_blank">[DSLPT] </a>
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!--</div>-->
      <!-- </div> -->
      </div>
    </div>



    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/swin_block.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Swin-Unet: Unet-like Pure Transformer for Medical Image Segmentation</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Yueyue Wang, Joy Chen, Dongsheng Jiang, Xiaopeng Zhang, Qi Tian, Manning Wang</div>
        <div class="paper-conf"><em>European Conference on Computer Vision Workshops (ECCVW) <font color="#0000dd"><b> <a href="https://scholar.google.com/citations?hl=en&vq=en&view_op=list_hcore&venue=cwIh2C-xo8kJ.2024" target="_blank">[Top 3 Most Cited ECCV Papers in Five Years]  </a></b></font></em>, 2022</div> 
        <!-- <div> -->
          <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://link.springer.com/chapter/10.1007/978-3-031-25066-8_9" target="_blank">[paper]</a>
        <!-- </div> -->
        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/HuCaoFighting/Swin-Unet?style=social" />
          <a href="https://github.com/HuCaoFighting/Swin-Unet" target="_blank">[Swin-Unet] </a>
          <a href="https://www.youtube.com/watch?v=ha1iphjz7S4&t=2s" target="_blank">[Video]</a>
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        </div>
      </div>
    </div>


    
    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/Fisheye.jpg">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Orientation-aware People Detection and Counting Method based on Overhead Fisheye Camera</div>
        <div class="paper-author"><font color="#0000dd"><b>Hu Cao</b></font>, Boyang Peng, Linxuan Jia, Bin Li, Alois Knoll, Guang Chen</div>
        <div class="paper-conf"><em>IEEE International Conference on Multisensor Fusion and Integration (MFI)<font color="#0000dd"></b></font></em>, 2022</div>
        <div>
          <img class="responsive-img icon" src="./images/pdf.png">
          <a href="https://ieeexplore.ieee.org/abstract/document/9913868" target="_blank">[paper]</a>
        </div>
        <!-- </div> -->
       <!--  <div> -->
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <!-- <img src="https://img.shields.io/github/stars/HuCaoFighting/Gaussian-based-Grasping?style=social" />
          <a href="https://github.com/HuCaoFighting/Gaussian-based-Grasping" target="_blank">[Efficient-Grasping] </a> -->
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!--</div>-->
      </div>
    </div>

    <hr class="Dense-hr">

  <!-- </div> -->
</div>
<!--<div align='right'> <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9" size="2">LEARN MORE>></font> </a></div> -->
</div>


</div>



<!--==========================================
                   Preprints
===========================================-->
<div class="section preprints-section scrollspy" id="preprints">

  <div class="row container">
    <div class="row">
      <div class="title">Preprints</div>
      <hr>
    </div>

    <div><font color="blue"><b>( <sup>‚Ä†</sup> indicates equal contribution, <sup>*</sup> indicates corresponding author, <sup>#</sup> indicates project lead)</b></font></div><br>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/ClipDomain.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">VLTSeg: Simple Transfer of CLIP-Based Vision-Language Representations for Domain Generalized Semantic Segmentation</div>
        <div class="paper-author">H√ºmmer Christoph, Schwonberg Manuel, Zhou Liangwei, <font color="#0000dd"><b>Hu Cao*</b></font>, Alois Knoll, Gottschalk Hanno</div>
        <!-- <div class="paper-conf"><em>IEEE Geoscience and Remote Sensing Letters <font color="red"><b>(GRSL, CCF-C)</b></font></em>, 2021</div> -->
        <!-- <div> -->
          <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
          <a href="https://arxiv.org/abs/2312.02021" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2101.10226-B31B1B.svg" /></a>
        <!-- </div> -->
       <!--  <div> -->
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <!-- <img src="https://img.shields.io/github/stars/HuCaoFighting/Gaussian-based-Grasping?style=social" />
          <a href="https://github.com/HuCaoFighting/Gaussian-based-Grasping" target="_blank">[Efficient-Grasping] </a> -->
         <!--  <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-Pytorch]</a>-->
        <!--</div>-->
      </div>
    </div>

    <hr class="preprints-hr">

  </div>

</div>


<!--==========================================
                   Footer
===========================================-->
<footer class="page-footer grey lighten-2">
  <div class="row">
    <div class="widgetContainer" style="width:300px; margin: 0 auto;">        
      <!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=JmtGDoLvSHQtPqCWd8cr5dhSABXJqV6QbEaaA2Gp1xU'></script> -->
      <script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=52alcfaz816&amp;m=0&amp;c=ff0000&amp;cr1=ffffff&amp;f=arial&amp;l=33" async="async"></script>
    </div>
  </div>
  <div class="footer-copyright center black-text">
    Copyright ¬© Hu Cao 2021
  </div>  
</footer>

<!--  Scripts-->
<script src="./files/jquery-2.1.1.min.js"></script>
<script src="./files/materialize.js"></script>
<script src="./files/aos.js"></script>
<script src="./init.js"></script>

</div><div class="jvectormap-tip"></div></body></html>